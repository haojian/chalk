---
layout: post
title: "隐私是个灰色地带."
description: "It's a Grey World."
tags: [research, phd, cn]
---

> 这篇文章改改停停，第一版写在17年6月，但是每隔一阵都有新的想法。写了差不多半年，最后发现得到的结论早就已经在Jason十年前的[job talk]()里面表述过了。

<img src=`_assets/resources/privacy_tech_market_legal_social.png`/>



12年纽约时报有一个影响很大的报道: Target可以比少女的爸爸更早知道未成年少女怀孕。孕妇在孕期会买很多特定的商品，如钙片，锌片，没有气味的乳液等等。Target通过统计购买记录，手动发现了25种产品可以和购买者是否怀孕有联系。甚至可以通过购买的商品，可以判断孕妇怀孕多久。这个例子是数据库应用的扩展。在那之前，最有名的案例是[沃尔玛发现买尿布的人经常一起买啤酒](https://www.theregister.co.uk/2006/08/15/beer_diapers/)。美国的青年男性一般喜欢周五晚上去酒吧喝啤酒。但是刚有小孩以后，因为小孩的压力，这些人就不能去酒吧了。所以，他们逛超市买尿布时，就会买一些啤酒回家喝。后来超市把尿布放在啤酒专柜旁边，啤酒的销量也因此提高。

Target这个新闻当时引起很大争议，因为未成年少女怀孕是一个敏感话题。类似的新闻还有很多。今年上半年，[Facebook被发现允许广告商通过个人的情感状态来推送广告](https://www.theguardian.com/technology/2017/may/01/facebook-advertising-data-insecure-teens)，因为Facebook当时有一个研究，发现他们可以通过分析青少年更新的文字来判断他们心情是否低落，是否自我怀疑。而到下半年，facebook主动宣传了另外一个故事，[facebook可以通过ai来阻止自杀](https://www.washingtonpost.com/news/the-switch/wp/2017/11/27/facebook-is-using-ai-to-try-to-prevent-suicide/?utm_term=.0fd95dbb7b3e)。同样的技术出现在了正反两个故事里。

技术是中性的。可以用来作恶，也可以用来行善。但是难的是美好的意愿，并不一定就导向好的结果。

回到Target这个故事上，这个故事的上下文要比那个标题党的题目更加有意思。Target是美国排名第二的零售商(第一是沃尔玛), 但是顾客去Target都只买某一类产品，比如文具或者小电器。Target期望成为一个一站式的购物商场，希望大家无论是买文具，买菜，买电子产品，买服装，都去他们那买。很多社会学和经济学研究都发现，当一个家庭有第一个小孩的时候，因为第一次当爸爸妈妈，全家会非常手忙脚乱，所以这个家庭的消费习惯会经历一次巨大的变化。Target之所以去判断怀孕，就是希望能够利用好这个机会来修正大家对Target的印象。当Target发现这个家庭有孕妇，他们就会给这个家庭寄特别设计的产品目录，告诉他们，我们不仅仅卖文具，我们还卖尿布，卖食物，卖婴儿服饰，等等。


如果我们把这些步骤分开来看:

1. Target 通过用户的会员卡来收集用户的购买行为。
2. Target 分析收集的数据来建立一些个性化模型，并给用户打各种标签，如怀孕。
3. Target 内部部门合作，将分析以后的结果分享给市场部门。
4. Target 市场部门向打了“怀孕” 标签的用户，发特别的产品目录。
5. 寄送产品目录的过程有可能被其他人看到了，例如目录不小心记错到了邻居那里。如果这个产品目录设计得太过明显，邻居可能因此猜到怀孕的事实。
6. 因为这段时间用户消费行为非常容易受影响，可能有一部分人一生的消费行为被改变了。


站在我的角度，1-5已经无法避免，让我不安的是第6点。这一套连续技利用了我情感上最脆弱的时候控制我的行为。过去一年，我一直试图销售这套理论给我身边的人，但并没有成功。

大部分认为这件事并没有任何问题。
- 有说这是Target在为我做个性化推荐，这是为了帮助我。
- 也有说，今天的整个广告系统和市场营销，甚至品牌建设，不就是这样的么。

这让我很沮丧。我隐约觉得这应该是一个很重要的问题，或者现在还没有那么重要，但是在可见的时间范围内，会变得越来越重要。

AI的本质是大规模的自动决策，很多过去不能实现的精准打击在未来都会成为现实。今天的品牌营销不能针对个人，所有的营销都是针对一个大的群体。广告营销不能指哪打哪，但AI是可以的。今年有一个关于uber动态定价策略的报道。[Uber发现用户手机电量比较低的时候，大家更愿意接受高动态定价](https://www.forbes.com/sites/amitchowdhry/2016/05/25/uber-low-battery/#6618b9cc74b3)。这个价格歧视和下雨天打的费上涨并不一样。用一个更夸张的例子，假如我有足够的技术精准到一个人，然后我知道他过年一定要回家，我能不能垄断他所有的机票火车票价钱，把价钱设到他愿意承担的上限？

[What Stays in Vegas](https://www.amazon.com/What-Stays-Vegas-Personal-Lifeblood/dp/1610396391)讲述了一个更加真实的故事。凯撒娱乐是拉斯维加斯一家赌场公司，CEO是一个哈佛大学的教授，他们的主要客户定位在小额玩家身上。这家公司最有名的是建立了一套非常完善的信息系统，他们知道每个客户的收入，职业，教育背景，以及过去的赌博行为。利用这些信息，他们知道每个人对于输钱的[痛点](https://www.smartbrief.com/original/2017/08/dangers-corporations-and-big-data)。痛点指一个人如果输了那么多钱，心里的负罪感会让他们离开赌场很久都不愿意回来。假如一个人的痛点是3000美金，当他输了这么多钱，这个赌场在几个月内都会丢失掉这个客户。但是如果他只输了2900就收手了，他依然很难过，但是下个星期他又会到赌场里来。这样对赌场而言是更有利的。所以赌场当发现一个客户接近于痛点的时候，就会想办法让顾客离开赌桌，比如提供一个免费食物，或者免费show的门票。

这样的未来我不知道会不会存在，但我倾向于法律会在合适的时间制止这些情况的发生。我一直坚持一个观点，坏人做坏事不可怕，因为坏人一旦暴露，就不能继续做坏事。我更担心的是好人做坏事，还以为自己在做好事。我的隐私研究




我不知道未来这样的事情会不会发生






====




> What happens here stays here.       Slogan of Las Vegas

"这个世界正在变得前所未有的危险。"


我们的隐私研究

我觉得隐私的研究要解决两个问题。一个是好人做坏事。



中国其实处在一个很危险的情况下，在商业环境里面，不应该有一个电商在这么大的规模上垄断。

，买电子
对于自己公司更大的期望


我们理想的世界是这个互联网是收费的互联网，我们看的每一个内容都要付钱，同样的，给我们推送的每一个广告都要付给我们钱。这样我们也可以构造出一个不一样的隐私世界。


这一套连续技cover了美国隐私法律里面完整的隐私定义。从collection=》invading。

最常见的观点是技术本身是中性的，关键看人怎么用。但怎么用才往正面走并不是那么一清二白。




我大部分时候觉得是应该拥抱这些技术改变的。就像人类进化一样，我们需要大量的试错成本。而且今天的我们也承担的起这些试错成本。我们不可能不犯错，我们真正需要的是不断的监管和自我反省，发现自己的错误。当错误发生的时候，有能力去改掉这些错误。


我对于这些

往好了用就是好，往坏了用就是坏。但是这个世界有太多的灰色地带。不是我们需要

最终解决所有问题最好的办法就是改善教育，把所有人教育成好人。但是这里面

往好了用

最常见的说法是技术本身是中立的，关键是看人怎么用。好人用就是好，坏人用就是坏。解决这个世界最好的办法，就是把所有人教育成好人。这里面归根到底，是动机。是好的动机，还是坏的动机？




隐私的研究有两部分，一方面是要发现坏人做坏事，另外一方面也要监管那些好人做的好事是否会有坏的影响。

类似的还有facebook可以在青少年心情低落的时候，给他们推送广告。



类似的还有很多，比如uber可以根据你的手机电池来决定你的surge prive，facebook可以在青少年心情低落的时候给他们推送广告。


我其实一直不喜欢所有和privacy有关的新闻以这种方式出现。类似的还有，uber可以根据你的收集电池来决定你的电池水平，facebook 可以在青少年心情低落的时候给他们推送广告。因为这些都挑了一些比较极端的例子，比如未成年怀孕少年，沉迷社交网络的青少年，等等。但是即便没有这些例子，隐私依然很重要。
我并不喜欢这种阴谋论的推断。今天的监管体系下，很少有公司能够肆意妄为。比如facebook没有动力去做这样的广告，除非法律和环境都已经成熟。uber也不敢冒天下之大不韪去用电池信息去做那些预测。


相反，真正的问题不是这些。这个世界开始变得越来越危险，不是因为机器可以像人一样思考，而是人像机器一样思考。


我对target那个例子有着和jason完全不一样的理解。

隐私在今天还是一个未来的问题。假如一个问题最严重的是100分，今天 温饱可能是30分，但是隐私只有1分，而手机上面的location data 只有0.1分。但是我们今天的科技发展，温饱这些问题会越来越小，相反，隐私这样的问题会越来越大。

今天数据的泄露是方方面面的。


就像几万年前我们需要带着武器才能出现在森林里，以后我们要带着电池才能


“今天，大家并没有那么关心隐私。但是，恰恰因为大家不够关心隐私，但隐私又那么重要，所以我们要做隐私研究。”
“不对。大家不是不关心隐私，大家只是不明白这些隐私泄露的发生。”

我并不是一个好的隐私研究员。我的导师jason是非常有名的研究员。开创了隐私在ubicomp的手机iot的领域。在10年前就预言，未来手机可以知道你的很多行为。你想要买什么，你想什么，你想要看什么。我在第一次和jason开会的时候，我就非常直接地和jason表示，这个我不明白为什么要这么关心隐私，而事实上公众非常不关心隐私。

但后来我也开始进入隐私这个领域做研究。

privacy to algorithms.


[How Target Figured Out A Teen Girl Was Pregnant Before Her Father Did](https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/#ef01ad466686)



[Facebook told advertisers it can identify teens feeling 'insecure' and 'worthless'](https://www.theguardian.com/technology/2017/may/01/facebook-advertising-data-insecure-teens)